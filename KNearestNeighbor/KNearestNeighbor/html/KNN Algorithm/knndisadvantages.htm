<html DIR="LTR" xmlns:MSHelp="http://msdn.microsoft.com/mshelp" xmlns:ddue="http://ddue.schemas.microsoft.com/authoring/2003/5" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:tool="http://www.microsoft.com/tooltip">
<head>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; CHARSET=Windows-1252"></META><META NAME="save" CONTENT="history"></META>
<title>k-NN Disadvantages</title>

<link rel="stylesheet" type="text/css" href="../local/Classic.css"></link>
<script src="../local/script.js"></script>
</head>

<body>

	<div id="header">
		<h1>k-Nearest Neighbor Disadvantages</h1>
	</div>

	<div id="mainSection">
		<div id="mainBody">
			<p class="runningHeader"></p>

			<p>There are various disadvantages to using the k-NN algorithm:</p>

			<ul>
				<li class="unordered">The model cannot be interpreted (there is no description of the learning concepts).<br /><br /></li>
				<li class="unordered">It is computationally expensive to find the k nearest neighbors when the dataset is sufficiently large.<br /><br /></li>
				<li class="unordered">Performance depends on the number of dimensions that we have. (Curse of dimensionality).<br /><br /></li>
			</ul>

			<p>What is the <u>curse of dimensionality</u>? The more dimensions that we have (attributes), the more training examples we need to approximate a decision. The number of examples that we have in a colume space decreases exponentially with the number of dimensions. This is especially bad for k-NN. If there are a large amount of dimensions (attributes) then the nearest neighbors may be very far away.</p>
		</div>

		<hr />
		<p />
	</div>
</body>
</html>